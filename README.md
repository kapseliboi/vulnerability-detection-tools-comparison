# vulnerability-detection-tools-comparison
This repository contains scripts for running multiple vulnerability detection tools at once


## Requirements

- Node.js >= 16 and npm >= 7
- Git
- OWASP Dependency Check CLI (I used version 6.2.2, installation: https://jeremylong.github.io/DependencyCheck/dependency-check-cli/)
- Yarn (required by dependency check)
- Ruby + bundle-audit (otherwise dependency check will throw errors when it tries to scan ruby code)
- Authenticated Snyk CLI installed (I used version 1.658.0)
- Authenticated GitHub CLI or unauthenticated with an access token
- Unix find command available in path
- GitHub.com enterprise account (without it dependabot results might be incorrect: https://docs.github.com/en/code-security/supply-chain-security/managing-vulnerabilities-in-your-projects-dependencies/troubleshooting-the-detection-of-vulnerable-dependencies#are-there-limits-which-affect-the-dependency-graph-data)

## Functionality

### How I used this script?

1. I used my search parameters in GithHub search (https://seart-ghs.si.usi.ch/) and downloaded the results as JSON from there

2. I would randomize the order of projects in the result file using command `node build/index.js randomizeSearchResultItemOrder --inputFiles results.json`. Note: this command requires running npm build first. You can also run this command with ts-node.

3. Then I would use the select command. I needed to use multiple GitHub searches so I had multiple files. I wanted to preserve their relative size in the project selection as well and to do that I used this command: `node build/index.js select --inputFiles jsResults.json tsResults.json --groupSize 100 --minDepCount 100 --limit 200`. Here I basically say that use these input files to find projects on GitHub which have at least 100 dependencies. Find 200 automatically filtered projects per input file and then proceed to manually select projects from them in groups of 100. The groups basically means that you preserve the relative sizes of the different input files even in the selected projects.

4. After I had done the selection I would just run `node --max-old-space-size=10240 --inspect -r ts-node/register src/index.ts execute` Note that this requires a lot of RAM. I also ran this command using tee to save all output like this: `node --max-old-space-size=10240 build/index.js execute 2>&1 | tee executeLog.txt`. Just in case I also had the `SAVE_TOOL_RESULTS_TO_FILES` environment variable set to true for dealing with potential errors without favoring the tools with errors (explained in the next step).

5. After this I would check the logs for errors and then fix the errors by running the execute command again but this time using the --useResultFiles=true, --project ERRORED_PROJECT and I commented already succesfully executed tools in src/detectionTools/index.ts to avoid running them again for no reason. The --useResultFiles=true was used because if new vulnerabilities would've been discovered between 1st run and this 2nd run then obviously the tools with errors would be favored. As result files are not supported for Dependabot I would prioritize errors with that as they can increase dynamically. Result files are also not supported for WhiteSource Bolt but it doesn't create new issues by itself. I also deleted the previous runs then with `delete toolExecution` when needed. To retain the execution time data for tools like dependency-check and npm audit I used the `--copyExecutionDuration=true` option.

6. After taking care of the errors I would check the manual reviews in the database and add suitable vulnerabilities and potential dependencies + dependency paths to database manually.

7. I would check the database for vulnerabilities with invalid internalIds using the command fixInternalIds

8. I would use the command interlinkVulnerabilities which tries to match other vulnerabilities in the database using identifiers and copies all available identifiers to maximize the linking between vulnerabilities in the database. In case of conflicts it will ask you which identifiers to preserve. If there was a clear mismatch I would just abort the command and make changes to the database manually and then re run the command.

9. I would use the command linkVulnerabilities to link vulnerabilities without enough identifiers to other vulnerabilities that have been detected for the same dependencies. The tool asks you if the other vulnerabilities in fact are the same vulnerability. I'm pretty sure this command is kinda buggy and I would definitely refactor it using the code from interlinkVulnerabilities if I were to do this again.

10. I would run interlinkVulnerabilities again to link the possible new information gathered in the previous step. 

11. I manually fixed severity ratings to be one of low, medium, high, critical or unknown

12. I started running the analyze commands to get results

### Select

Selects projects based on a provided JSON file which has to be produced by GitHub Search or be in the same format. It checks the amount of dependencies in the repository and
if it meets the minimum requirement for dependencies it gives a link to the user to the repository for the user to manually inspect its suitability.
Then the user simply selects if it accepts it or not. Then the project is saved to the database for later analysis. This project uses TypeORM so the type of database is freely configurable.
Some extra work is also done regarding later analysis with repository based tools.
The project is forked and Dependabot is enabled using an authenticated GitHub CLI.

### Execute

Produces results with all the tools and saves them to database and if saving to files is enabled then also to ./results/${GitHub username}/${Repository name}/${Commit hash}


## TODO

- Add better way for handling manual reviews
- Reorganize code, e.g. util.ts -files are pretty horrible
- RetireJS handling, now the internalId is the description
- Rework the whole manual review / project error stuff. Now manual review is pretty usable but project error is outdated.
- Use a real logging library instead of console.log. This would make the code a lot cleaner.
- Maybe some error handling for database commands?
- Add linter to the project
- Handle OWASP DC "CWE as name with multiple vulnerabilities in one" -cases correctly. Now some vulnerabilities will be left out
