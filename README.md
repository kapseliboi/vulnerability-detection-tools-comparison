# vulnerability-detection-tools-comparison
This repository contains scripts for running multiple vulnerability detection tools at once


## Requirements

- Node.js >= 16 and npm >= 7
- Git
- OWASP Dependency Check CLI (I used version 6.2.2, installation: https://jeremylong.github.io/DependencyCheck/dependency-check-cli/)
- Yarn (required by dependency check)
- Ruby + bundle-audit (otherwise dependency check will throw errors when it tries to scan ruby code)
- Authenticated Snyk CLI installed (I used version 1.658.0)
- Authenticated GitHub CLI or unauthenticated with an access token
- Unix find command available in path
- GitHub.com enterprise account (without it dependabot results might be incorrect: https://docs.github.com/en/code-security/supply-chain-security/managing-vulnerabilities-in-your-projects-dependencies/troubleshooting-the-detection-of-vulnerable-dependencies#are-there-limits-which-affect-the-dependency-graph-data)

## Functionality

### How I used this script?

1. I used my search parameters in GithHub search (https://seart-ghs.si.usi.ch/) and downloaded the results as JSON from there

2. I would randomize the order of projects in the result file using command `node build/index.js randomizeSearchResultItemOrder --inputFiles results.json`. Note: this command requires running npm build first. You can also run this command with ts-node.

3. Then I would use the select command. I needed to use multiple GitHub searches so I had multiple files. I wanted to preserve their relative size in the project selection as well and to do that I used this command: `node build/index.js select --inputFiles jsResults.json tsResults.json --groupSize 100 --minDepCount 100 --limit 200`. Here I basically say that use these input files to find projects on GitHub which have at least 100 dependencies. Find 200 automatically filtered projects per input file and then proceed to manually select projects from them in groups of 100. The groups basically means that you preserve the relative sizes of the different input files even in the selected projects.

4. After I had done the selection I would just run `node --max-old-space-size=10240 --inspect -r ts-node/register src/index.ts execute` Note that this requires a lot of RAM. I also ran this command using tee to save all output like this: `node --max-old-space-size=10240 build/index.js execute 2>&1 | tee executeLog.txt`. Just in case I also had the `SAVE_TOOL_RESULTS_TO_FILES` environment variable set to true for dealing with potential errors without favoring the tools with errors (explained in the next step).

5. After this I would check the logs for errors and then fix the errors by running the execute command again but this time using the --useResultFiles=true, --project ERRORED_PROJECT and I commented already succesfully executed tools in src/detectionTools/index.ts to avoid running them again for no reason. The --useResultFiles=true was used because if new vulnerabilities would've been discovered between 1st run and this 2nd run then obviously the tools with errors would be favored. As result files are not supported for Dependabot I would prioritize errors with that as they can increase dynamically. Result files are also not supported for WhiteSource Bolt but it doesn't create new issues by itself. I also deleted the previous runs then with `delete toolExecution` when needed. To retain the execution time data for tools like dependency-check and npm audit I used the `--copyExecutionDuration=true` option.

6. After taking care of the errors I would check the manual reviews in the database and add suitable vulnerabilities and potential dependencies + dependency paths to database manually.

7. I would manually check the database for all dependencies without universal identifiers (GHSA, npm, cve) and try to find those for them and add them to the database.

8. I would run owaspCleanup command. They are the only tools that don't have a centralized vulnerability repository for themselves so the results end up containing duplicate vulnerabilities.


### Select

Selects projects based on a provided JSON file which has to be produced by GitHub Search or be in the same format. It checks the amount of dependencies in the repository and
if it meets the minimum requirement for dependencies it gives a link to the user to the repository for the user to manually inspect its suitability.
Then the user simply selects if it accepts it or not. Then the project is saved to the database for later analysis. This project uses TypeORM so the type of database is freely configurable.
Some extra work is also done regarding later analysis with repository based tools.
The project is forked and Dependabot is enabled using an authenticated GitHub CLI.

### Execute

Produces results with all the tools and saves them to database and if saving to files is enabled then also to ./results/${GitHub username}/${Repository name}/${Commit hash}


## TODO

- Add better way for handling manual reviews
- Reorganize code, e.g. util.ts -files are pretty horrible
- RetireJS handling, now the internalId is the description
- Rework the whole manual review / project error stuff. Now manual review is pretty usable but project error is outdated.
- Use a real logging library instead of console.log. This would make the code a lot cleaner.
- Maybe some error handling for database commands?
- Add linter to the project
